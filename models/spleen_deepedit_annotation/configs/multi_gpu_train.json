{
    "device": "$torch.device('cuda:' + os.environ['LOCAL_RANK'])",
    "network": {
        "_target_": "torch.nn.parallel.DistributedDataParallel",
        "module": "$@network_def.to(@device)",
        "device_ids": [
            "@device"
        ]
    },
    "train#sampler": {
        "_target_": "DistributedSampler",
        "dataset": "@train#dataset",
        "even_divisible": true,
        "shuffle": true
    },
    "train#dataloader#sampler": "@train#sampler",
    "train#dataloader#shuffle": false,
    "train#trainer#train_handlers": "$@train#handlers[: -2 if dist.get_rank() > 0 else None]",
    "validate#sampler": {
        "_target_": "DistributedSampler",
        "dataset": "@validate#dataset",
        "even_divisible": false,
        "shuffle": false
    },
    "validate#dataloader#sampler": "@validate#sampler",
    "validate#handlers": [
        {
            "_target_": "EarlyStopHandler",
            "_disabled_": "$not @early_stop",
            "trainer": null,
            "patience": 1,
            "score_function": "$scripts.score_function",
            "min_delta": 0.01
        },
        {
            "_target_": "StatsHandler",
            "_disabled_": "$dist.get_rank() > 0",
            "iteration_log": false
        },
        {
            "_target_": "TensorBoardStatsHandler",
            "_disabled_": "$dist.get_rank() > 0",
            "log_dir": "@output_dir",
            "iteration_log": false
        },
        {
            "_target_": "CheckpointSaver",
            "_disabled_": "$dist.get_rank() > 0",
            "save_dir": "@ckpt_dir",
            "save_dict": {
                "model": "@network"
            },
            "save_key_metric": true,
            "key_metric_filename": "model.pt"
        }
    ],
    "initialize": [
        "$import torch.distributed as dist",
        "$dist.is_initialized() or dist.init_process_group(backend='nccl')",
        "$torch.cuda.set_device(@device)",
        "$monai.utils.set_determinism(seed=123)"
    ],
    "run": [
        "$@validate#handlers#0.set_trainer(trainer=@train#trainer) if @early_stop else None",
        "$@train#trainer.run()"
    ],
    "finalize": [
        "$dist.is_initialized() and dist.destroy_process_group()"
    ]
}
