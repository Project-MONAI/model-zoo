---
imports:
- "$import glob"
- "$import os"
- "$import scripts.monai_utils"
workflow_type: inference
input_channels: 1
output_classes: 4
output_channels: 4
# arch_ckpt_path: "$@bundle_root + '/models/dynunet_FT.pt'"
# arch_ckpt: "$torch.load(@arch_ckpt_path, map_location=torch.device('cuda'))"
bundle_root: "."
output_dir: "$@bundle_root + '/eval/dynunet_FT'"
dataset_dir: "/processed/Public/CT_TotalSegmentator/TS_split/test/"
data_list_file_path: "$@bundle_root + '/configs/TS_test.json'"
datalist: "$monai.data.load_decathlon_datalist(@data_list_file_path, data_list_key='validation')"
device: "$torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
spatial_size:
- 96
- 96
- 96
spatial_dims: "$len(@spatial_size)"
labels:
  background: 0
  liver: 1
  spleen: 2
  pancreas: 3
network_def:
  _target_: monai.networks.nets.DynUNet
  spatial_dims: "@spatial_dims"
  in_channels: "@input_channels"
  out_channels: "@output_channels"
  kernel_size:
  - 3
  - 3
  - 3
  - 3
  - 3
  - 3
  strides:
  - 1
  - 2
  - 2
  - 2
  - 2
  -
    - 2
    - 2
    - 1
  upsample_kernel_size:
  - 2
  - 2
  - 2
  - 2
  -
    - 2
    - 2
    - 1
  norm_name: "instance"
  deep_supervision: false
  res_block: true
network: "$@network_def.to(@device)"
image_key: image
preprocessing:
  _target_: Compose
  transforms:
  - _target_: LoadImaged
    keys: "@image_key"
    reader: ITKReader
  - _target_: EnsureChannelFirstd
    keys: "@image_key"
  - _target_: Orientationd
    keys: image
    axcodes: RAS
  - _target_: Spacingd
    keys:
    - "@image_key"
    pixdim:
    - 1.5
    - 1.5
    - 3.0
    mode:
    - bilinear
  - _target_: ScaleIntensityRanged
    keys: "@image_key"
    a_min: -250
    a_max: 400
    b_min: 0
    b_max: 1
    clip: true
  - _target_: CropForegroundd
    keys:
    - "@image_key"
    source_key: "@image_key"
    mode:
    - "minimum"
  - _target_: EnsureTyped
    keys: image
  - _target_: CastToTyped
    keys: "@image_key"
    dtype: "$torch.float32"
dataset:
  _target_: Dataset
  data: "@datalist"
  transform: "@preprocessing"
dataloader:
  _target_: DataLoader
  dataset: "@dataset"
  batch_size: 1
  shuffle: false
  num_workers: 4
inferer:
  _target_: SlidingWindowInferer
  roi_size:
  - 96
  - 96
  - 96
  sw_batch_size: 4
  overlap: 0.75
postprocessing:
  _target_: Compose
  transforms:
  - _target_: Activationsd
    keys: pred
    softmax: true
  - _target_: Invertd
    keys: pred
    transform: "@preprocessing"
    orig_keys: image
    meta_key_postfix: meta_dict
    nearest_interp: false
    to_tensor: true
  - _target_: AsDiscreted
    keys: pred
    argmax: true
  - _target_: SaveImaged
    keys: pred
    meta_keys: pred_meta_dict
    output_dir: "@output_dir"
    separate_folder: false
    output_dtype: "$torch.int16"
handlers:
- _target_: CheckpointLoader
  load_path: "$@bundle_root + '/models/dynunet_FT.pt'"
  load_dict:
    model: "@network"
- _target_: StatsHandler
  iteration_log: false
evaluator:
  _target_: SupervisedEvaluator
  device: "@device"
  val_data_loader: "@dataloader"
  network: "@network"
  inferer: "@inferer"
  postprocessing: "@postprocessing"
  val_handlers: "@handlers"
  amp: true
initialize:
- "$setattr(torch.backends.cudnn, 'benchmark', True)"
run:
- "$@evaluator.run()"
